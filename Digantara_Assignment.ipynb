{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqzKgUEGqCgF1JD8DC/M2b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SimranSingh98/Digantara_Assignment/blob/main/Digantara_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parsing the TLE Data**"
      ],
      "metadata": {
        "id": "5VPervrtVQZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sgp4"
      ],
      "metadata": {
        "id": "4whaM4ewYxsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hms2lvXQtgsA",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "def read_tle_file(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    tle_data = []\n",
        "    for i in range(0, len(lines), 3):\n",
        "        title_line = lines[i].strip()\n",
        "        line1 = lines[i + 1].strip()\n",
        "        line2 = lines[i + 2].strip()\n",
        "        tle_data.append((title_line, line1, line2))\n",
        "\n",
        "    return tle_data\n",
        "\n",
        "# Given File\n",
        "filename = '30000sats.txt'\n",
        "tle_data = read_tle_file(filename)\n",
        "\n",
        "# Displaying parsed TLE data\n",
        "# for tle in tle_data:\n",
        "#     print(\"Title:\", tle[0])\n",
        "#     print(\"Line 1:\", tle[1])\n",
        "#     print(\"Line 2:\", tle[2])\n",
        "#     print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Get Satellite location**"
      ],
      "metadata": {
        "id": "zefdIqUUVZjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from sgp4.api import Satrec, jday\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def get_satellite_location(tle_data, output_file):\n",
        "    # now = datetime.utcnow()\n",
        "    # Open the CSV file within the context of the `with` block\n",
        "    with open(output_file, 'w', newline='') as csvfile:\n",
        "        fieldnames = ['time', 'Lx', 'Ly', 'Lz', 'Vx', 'Vy', 'Vz']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        for title, line1, line2 in tle_data:\n",
        "            satellite = Satrec.twoline2rv(line1, line2)\n",
        "\n",
        "            # Set start_time close to the TLE epoch (30sats - 54th day, 30000sats - 238th day)\n",
        "            start_time = datetime(2023, 8, 25, 0, 0, 0)\n",
        "            end_time = start_time + timedelta(days=1)\n",
        "\n",
        "            current_time = start_time\n",
        "            while current_time <= end_time:\n",
        "                jd, fr = jday(current_time.year, current_time.month, current_time.day,\n",
        "                              current_time.hour, current_time.minute, current_time.second)\n",
        "\n",
        "                error_code, r, v = satellite.sgp4(jd, fr)\n",
        "\n",
        "                if error_code == 0:\n",
        "                    # Write the result to the CSV file\n",
        "                    writer.writerow({\n",
        "                        'time': current_time.isoformat(),\n",
        "                        'Lx': r[0],\n",
        "                        'Ly': r[1],\n",
        "                        'Lz': r[2],\n",
        "                        'Vx': v[0],\n",
        "                        'Vy': v[1],\n",
        "                        'Vz': v[2]\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"Error in SGP4 propagation for {title}: {error_code}\")\n",
        "\n",
        "                current_time += timedelta(minutes=1)\n",
        "\n",
        "\n",
        "output_file = 'satellite_positions_and_velocities.csv'\n",
        "get_satellite_location(tle_data, output_file)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RDJIWAYhUUJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Convert data to lat long alt format**"
      ],
      "metadata": {
        "id": "rOmhO3qvi8Ks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import csv\n",
        "import pyproj\n",
        "\n",
        "import pyproj\n",
        "\n",
        "def ecef2lla(i, pos_x, pos_y, pos_z):\n",
        "    # Define the ECEF projection based on WGS84 ellipsoid\n",
        "    ecef = pyproj.Proj(proj=\"geocent\", ellps=\"WGS84\", datum=\"WGS84\")\n",
        "\n",
        "    # Define the LLA (latitude, longitude, altitude) projection\n",
        "    lla = pyproj.Proj(proj=\"latlong\", ellps=\"WGS84\", datum=\"WGS84\")\n",
        "\n",
        "    # Create a transformer object to convert ECEF to LLA\n",
        "    transformer = pyproj.Transformer.from_proj(ecef, lla)\n",
        "\n",
        "    # Transform ECEF (X, Y, Z) to LLA (longitude, latitude, altitude)\n",
        "    lona, lata, alta = transformer.transform(pos_x[i], pos_y[i], pos_z[i], radians=False)\n",
        "\n",
        "    # Return the transformed coordinates\n",
        "    return lona, lata, alta\n",
        "\n",
        "\n",
        "# Step 1: Read the CSV file and extract Lx, Ly, Lz values\n",
        "input_file = 'satellite_positions_and_velocities.csv'\n",
        "Lx, Ly, Lz = [], [], []\n",
        "\n",
        "with open(input_file, 'r') as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    for row in reader:\n",
        "        Lx.append(float(row['Lx']))\n",
        "        Ly.append(float(row['Ly']))\n",
        "        Lz.append(float(row['Lz']))\n",
        "\n",
        "# Step 2: Convert the extracted ECEF coordinates to LLA format\n",
        "# start_time = time.time()\n",
        "\n",
        "lla_results = [ecef2lla(i, Lx, Ly, Lz) for i in range(len(Lx))]\n",
        "\n",
        "# end_time = time.time()\n",
        "# print(f\"filter_results execution time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Step 3: Output the LLA results\n",
        "output_file = 'satellite_latlongalt.csv'\n",
        "with open(output_file, 'w', newline='') as csvfile:\n",
        "    fieldnames = ['Longitude', 'Latitude', 'Altitude']\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "\n",
        "    for lon, lat, alt in lla_results:\n",
        "        writer.writerow({'Longitude': lon, 'Latitude': lat, 'Altitude': alt})\n",
        "\n",
        "# Print the LLA results (optional)\n",
        "# for lon, lat, alt in lla_results:\n",
        "#     print(f\"Longitude: {lon}, Latitude: {lat}, Altitude: {alt}\")\n"
      ],
      "metadata": {
        "id": "WJO998hoUUHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Find when it is going from over certain lat long region.**"
      ],
      "metadata": {
        "id": "oqdwBkfFmBCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def is_within_bounds(lat, lon, lat_min, lat_max, lon_min, lon_max):\n",
        "    \"\"\"Check if a given lat/lon is within the specified bounds.\"\"\"\n",
        "    return lat_min <= lat <= lat_max and lon_min <= lon <= lon_max\n",
        "\n",
        "def filter_results(input_file, output_file):\n",
        "    # Ask user for the four coordinates\n",
        "    # print(\"Enter the latitude and longitude for the four corners of the rectangle:\")\n",
        "\n",
        "    lat1 = 100.66673 #float(input(\"Latitude 1: \"))\n",
        "    lon1 = 20.58196 #float(input(\"Longitude 1: \"))\n",
        "    lat2 = 100.74973 #float(input(\"Latitude 2: \"))\n",
        "    lon2 = -12.64459 #float(input(\"Longitude 2: \"))\n",
        "    lat3 = -100.09096 #float(input(\"Latitude 3: \"))\n",
        "    lon3 = 50.71009 #float(input(\"Longitude 3: \"))\n",
        "    lat4 = -100.32309 #float(input(\"Latitude 4: \"))\n",
        "    lon4 = 100.79778 #float(input(\"Longitude 4: \"))\n",
        "\n",
        "    # Determine the bounding box\n",
        "    lat_min = min(lat1, lat2, lat3, lat4)\n",
        "    lat_max = max(lat1, lat2, lat3, lat4)\n",
        "    lon_min = min(lon1, lon2, lon3, lon4)\n",
        "    lon_max = max(lon1, lon2, lon3, lon4)\n",
        "\n",
        "    print(f\"Bounding box: Lat ({lat_min}, {lat_max}), Lon ({lon_min}, {lon_max})\")\n",
        "\n",
        "    # Open the CSV file containing the LLA data\n",
        "    with open(input_file, 'r') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        filtered_results = []\n",
        "\n",
        "        # Print some sample data\n",
        "        print(\"Sample data:\")\n",
        "        for i, row in enumerate(reader):\n",
        "            if i < 5:  # Print the first 5 rows as a sample\n",
        "                print(row)\n",
        "            lat = float(row['Latitude'])\n",
        "            lon = float(row['Longitude'])\n",
        "\n",
        "            # Filter based on the bounding box\n",
        "            if is_within_bounds(lat, lon, lat_min, lat_max, lon_min, lon_max):\n",
        "                filtered_results.append(row)\n",
        "\n",
        "    # Write the filtered results to a new CSV file\n",
        "    with open(output_file, 'w', newline='') as csvfile:\n",
        "        fieldnames = ['Longitude', 'Latitude', 'Altitude']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        for row in filtered_results:\n",
        "            writer.writerow(row)\n",
        "\n",
        "    # Optionally, print filtered results\n",
        "    # if filtered_results:\n",
        "    #     print(f\"Filtered results ({len(filtered_results)} entries):\")\n",
        "    #     for row in filtered_results:\n",
        "    #         print(f\"Longitude: {row['Longitude']}, Latitude: {row['Latitude']}, Altitude: {row['Altitude']}\")\n",
        "    # else:\n",
        "    #     print(\"No results found within the specified bounds.\")\n",
        "\n",
        "# Input and output files\n",
        "input_file = 'satellite_latlongalt.csv'\n",
        "output_file = 'filtered_satellite_positions.csv'\n",
        "\n",
        "# Call the function to filter results based on user input\n",
        "filter_results(input_file, output_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIfbreK9UUAr",
        "outputId": "6ae8174f-da99-429c-be62-23b5b4f32421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the latitude and longitude for the four corners of the rectangle:\n",
            "Bounding box: Lat (-100.32309, 100.74973), Lon (-12.64459, 100.79778)\n",
            "Sample data:\n",
            "{'Longitude': '28.55127073937771', 'Latitude': '-90.0', 'Altitude': '-6352498.518419408'}\n",
            "{'Longitude': '32.62178825418735', 'Latitude': '-90.0', 'Altitude': '-6352291.224795465'}\n",
            "{'Longitude': '36.97259264989291', 'Latitude': '-90.0', 'Altitude': '-6352104.268830082'}\n",
            "{'Longitude': '41.621819950967634', 'Latitude': '-90.0', 'Altitude': '-6351938.497879223'}\n",
            "{'Longitude': '46.58021900573466', 'Latitude': '-90.0', 'Altitude': '-6351794.6630765265'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Optimize code to reduce computation time**"
      ],
      "metadata": {
        "id": "g8NBtnFusZvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Not using GPU (just multi-threading)\n",
        "\n",
        "from multiprocessing import Pool\n",
        "from datetime import datetime, timedelta\n",
        "from sgp4.api import Satrec, jday\n",
        "import csv\n",
        "import time\n",
        "\n",
        "# Function to get satellite position and velocity for a single satellite\n",
        "def get_satellite_location_single(tle):\n",
        "    title_line, tle1, tle2 = tle  # Unpacking three elements now\n",
        "    satellite = Satrec.twoline2rv(tle1, tle2)\n",
        "    results = []\n",
        "    now = datetime(2023, 2, 24, 0, 0, 0)\n",
        "    for minute in range(1440):  # 24 hours * 60 minutes\n",
        "        time = now + timedelta(minutes=minute)\n",
        "        jd, fr = jday(time.year, time.month, time.day, time.hour, time.minute, time.second)\n",
        "        e, r, v = satellite.sgp4(jd, fr)\n",
        "        results.append((time, r[0], r[1], r[2], v[0], v[1], v[2]))\n",
        "    return results\n",
        "\n",
        "# Function to handle parallel processing\n",
        "def get_satellite_location_parallel(tle_data):\n",
        "    with Pool() as pool:\n",
        "        results = pool.map(get_satellite_location_single, tle_data)\n",
        "    return [item for sublist in results for item in sublist]\n",
        "\n",
        "# Function to write results to a CSV file\n",
        "def write_results_to_csv(results, filename):\n",
        "    with open(filename, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(['Time', 'Lx', 'Ly', 'Lz', 'Vx', 'Vy', 'Vz'])\n",
        "        writer.writerows(results)\n",
        "\n",
        "# Main execution block\n",
        "if __name__ == \"__main__\":\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Read TLE data\n",
        "    filename = '30sats.txt'\n",
        "    tle_data_large = read_tle_file(filename)\n",
        "\n",
        "    # Calculate satellite positions in parallel\n",
        "    satellite_positions_optimized = get_satellite_location_parallel(tle_data_large)\n",
        "\n",
        "    # Write results to CSV\n",
        "    write_results_to_csv(satellite_positions_optimized, 'satellite_positions_gpu.csv')\n",
        "\n",
        "    # Calculate and print the execution time\n",
        "    execution_time = time.time() - start_time\n",
        "    print(f\"Execution Time: {execution_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "kogBOv4x3ozy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f72beb5e-11a1-4f33-ae74-f29a7373337f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time: 0.82 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install CuPy with CUDA 12.x support\n",
        "!pip install cupy-cuda12x\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "VwPe4uPGKbNP",
        "outputId": "1effc6b6-b138-46df-ee5b-f60e36350ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cupy-cuda12x\n",
            "  Downloading cupy_cuda12x-13.2.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x) (1.26.4)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x) (0.8.2)\n",
            "Downloading cupy_cuda12x-13.2.0-cp310-cp310-manylinux2014_x86_64.whl (89.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.5/89.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cupy-cuda12x\n",
            "Successfully installed cupy-cuda12x-13.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cupy",
                  "cupy_backends",
                  "cupyx"
                ]
              },
              "id": "5477275db4ba46b49ab553fb8474475d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Get Satellite location**"
      ],
      "metadata": {
        "id": "O7u3aJDEWS_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from sgp4.api import Satrec, jday\n",
        "import time\n",
        "import csv\n",
        "\n",
        "def compute_julian_dates(start_time, minutes):\n",
        "    \"\"\"Compute Julian Dates for a range of minutes on CPU.\"\"\"\n",
        "    time_deltas = np.arange(minutes) * 60  # Compute the number of seconds for each minute\n",
        "    times = [start_time + timedelta(seconds=int(delta)) for delta in time_deltas]\n",
        "    jd, fr = zip(*[jday(t.year, t.month, t.day, t.hour, t.minute, t.second) for t in times])\n",
        "    return np.array(jd), np.array(fr)\n",
        "\n",
        "def get_satellite_location_gpu(tle_data):\n",
        "    results = []\n",
        "\n",
        "    now = datetime(2023, 2, 24, 0, 0, 0)\n",
        "    minutes = 1440  # 24 hours * 60 minutes\n",
        "\n",
        "    # Precompute Julian Dates on CPU\n",
        "    jd_cpu, fr_cpu = compute_julian_dates(now, minutes)\n",
        "\n",
        "    # Transfer Julian Dates to GPU\n",
        "    jd_gpu = cp.array(jd_cpu, dtype=cp.float64)\n",
        "    fr_gpu = cp.array(fr_cpu, dtype=cp.float64)\n",
        "\n",
        "    for tle in tle_data:\n",
        "        title_line, tle1, tle2 = tle\n",
        "        satellite = Satrec.twoline2rv(tle1, tle2)\n",
        "\n",
        "        # Pre-allocate space for the results\n",
        "        positions = cp.zeros((minutes, 6), dtype=cp.float64)  # 3 for position (x, y, z) and 3 for velocity (vx, vy, vz)\n",
        "\n",
        "        # Run SGP4 on the GPU for all times\n",
        "        for i in range(minutes):\n",
        "            e, r, v = satellite.sgp4(jd_gpu[i].item(), fr_gpu[i].item())\n",
        "            positions[i, :3] = cp.array(r, dtype=cp.float64)   # Convert tuple to CuPy array\n",
        "            positions[i, 3:] = cp.array(v, dtype=cp.float64)\n",
        "\n",
        "        results.append(cp.asnumpy(positions))\n",
        "\n",
        "    return results\n",
        "\n",
        "# Main execution block\n",
        "if __name__ == \"__main__\":\n",
        "    start_time = time.time()  # Correctly initialize start_time with time.time()\n",
        "\n",
        "    # Calculate satellite positions using GPU\n",
        "    satellite_positions_gpu = get_satellite_location_gpu(tle_data)\n",
        "\n",
        "    # Optionally: Write results to a CSV file\n",
        "    with open('satellite_positions_gpu.csv', 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['Lx', 'Ly', 'Lz', 'Vx', 'Vy', 'Vz'])\n",
        "        for positions in satellite_positions_gpu:\n",
        "            writer.writerows(positions)\n",
        "\n",
        "    # Calculate and print the execution time\n",
        "    execution_time = time.time() - start_time\n",
        "    print(f\"Execution Time: {execution_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "afVizi8h3oxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Convert data to lat long alt format**."
      ],
      "metadata": {
        "id": "hXHue4YQWVjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pyproj\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "import time\n",
        "\n",
        "def ecef2lla_cpu(pos_x, pos_y, pos_z):\n",
        "    \"\"\"Convert ECEF coordinates to LLA using the CPU.\"\"\"\n",
        "    # Define the ECEF projection based on WGS84 ellipsoid\n",
        "    ecef = pyproj.Proj(proj=\"geocent\", ellps=\"WGS84\", datum=\"WGS84\")\n",
        "\n",
        "    # Define the LLA (latitude, longitude, altitude) projection\n",
        "    lla = pyproj.Proj(proj=\"latlong\", ellps=\"WGS84\", datum=\"WGS84\")\n",
        "\n",
        "    # Create a transformer object to convert ECEF to LLA\n",
        "    transformer = pyproj.Transformer.from_proj(ecef, lla)\n",
        "\n",
        "    # Convert GPU arrays to NumPy arrays\n",
        "    pos_x_np = cp.asnumpy(pos_x)\n",
        "    pos_y_np = cp.asnumpy(pos_y)\n",
        "    pos_z_np = cp.asnumpy(pos_z)\n",
        "\n",
        "    # Transform ECEF (X, Y, Z) to LLA (longitude, latitude, altitude) on CPU\n",
        "    lona, lata, alta = transformer.transform(pos_x_np, pos_y_np, pos_z_np, radians=False)\n",
        "\n",
        "    return lona, lata, alta\n",
        "\n",
        "# Step 1: Read the CSV file and extract Lx, Ly, Lz values\n",
        "input_file = 'satellite_positions_gpu.csv'\n",
        "Lx, Ly, Lz = [], [], []\n",
        "\n",
        "with open(input_file, 'r') as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    for row in reader:\n",
        "        Lx.append(float(row['Lx']))\n",
        "        Ly.append(float(row['Ly']))\n",
        "        Lz.append(float(row['Lz']))\n",
        "\n",
        "# Convert lists to CuPy arrays\n",
        "Lx_cp = cp.array(Lx)\n",
        "Ly_cp = cp.array(Ly)\n",
        "Lz_cp = cp.array(Lz)\n",
        "\n",
        "# Step 2: Convert the extracted ECEF coordinates to LLA format\n",
        "start_time = time.time()\n",
        "\n",
        "# Perform the conversion using CPU (after transferring data from GPU)\n",
        "lona, lata, alta = ecef2lla_cpu(Lx_cp, Ly_cp, Lz_cp)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Conversion execution time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Step 3: Output the LLA results to a CSV file\n",
        "output_file = 'satellite_latlongalt_gpu.csv'\n",
        "with open(output_file, 'w', newline='') as csvfile:\n",
        "    fieldnames = ['Longitude', 'Latitude', 'Altitude']\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "\n",
        "    for lon, lat, alt in zip(lona, lata, alta):\n",
        "        writer.writerow({'Longitude': lon, 'Latitude': lat, 'Altitude': alt})\n",
        "\n",
        "# Optionally: Print the LLA results\n",
        "# for lon, lat, alt in zip(lona, lata, alta):\n",
        "#     print(f\"Longitude: {lon}, Latitude: {lat}, Altitude: {alt}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjPaCVxSWXHs",
        "outputId": "93337e7b-318b-4bb7-a88a-5a788952657f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversion execution time: 0.02 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Find when it is going from over certain lat long\n",
        "region.**."
      ],
      "metadata": {
        "id": "4d7rhrK1W5mk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import cupy as cp\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Define CUDA kernel for filtering\n",
        "filter_kernel = cp.RawKernel(r'''\n",
        "extern \"C\" __global__\n",
        "void filter_data(const float* latitudes, const float* longitudes,\n",
        "                 float lat_min, float lat_max, float lon_min, float lon_max,\n",
        "                 int* mask, int num_elements) {\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (idx < num_elements) {\n",
        "        float lat = latitudes[idx];\n",
        "        float lon = longitudes[idx];\n",
        "        if (lat >= lat_min && lat <= lat_max && lon >= lon_min && lon <= lon_max) {\n",
        "            mask[idx] = 1;\n",
        "        } else {\n",
        "            mask[idx] = 0;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "''', 'filter_data')\n",
        "\n",
        "def load_data_from_csv(input_file):\n",
        "    \"\"\"Load latitude and longitude data from CSV file.\"\"\"\n",
        "    latitudes = []\n",
        "    longitudes = []\n",
        "    with open(input_file, 'r') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        for row in reader:\n",
        "            latitudes.append(float(row['Latitude']))\n",
        "            longitudes.append(float(row['Longitude']))\n",
        "    return np.array(latitudes), np.array(longitudes)\n",
        "\n",
        "def filter_results(input_file, output_file):\n",
        "    # Bounding box coordinates (in degrees)\n",
        "    lat1, lon1 = 40.66673, 20.58196\n",
        "    lat2, lon2 = 50.74973, -12.64459\n",
        "    lat3, lon3 = -10.09096, 50.71009\n",
        "    lat4, lon4 = -20.32309, 100.79778\n",
        "\n",
        "    lat_min = min(lat1, lat2, lat3, lat4)\n",
        "    lat_max = max(lat1, lat2, lat3, lat4)\n",
        "    lon_min = min(lon1, lon2, lon3, lon4)\n",
        "    lon_max = max(lon1, lon2, lon3, lon4)\n",
        "\n",
        "    print(f\"Bounding box: Lat ({lat_min}, {lat_max}), Lon ({lon_min}, {lon_max})\")\n",
        "\n",
        "    # Load data from CSV file\n",
        "    latitudes, longitudes = load_data_from_csv(input_file)\n",
        "    num_elements = len(latitudes)\n",
        "    print(f\"Data loaded: {num_elements} entries\")\n",
        "\n",
        "    # Transfer data to GPU\n",
        "    latitudes_cp = cp.asarray(latitudes)\n",
        "    longitudes_cp = cp.asarray(longitudes)\n",
        "    mask_cp = cp.zeros(num_elements, dtype=cp.int32)\n",
        "\n",
        "    # Define CUDA kernel grid and block size\n",
        "    block_size = 256\n",
        "    grid_size = (num_elements + block_size - 1) // block_size\n",
        "\n",
        "    # Launch CUDA kernel\n",
        "    start_time = time.time()\n",
        "    filter_kernel((grid_size,), (block_size,), (latitudes_cp, longitudes_cp,\n",
        "                                                lat_min, lat_max,\n",
        "                                                lon_min, lon_max,\n",
        "                                                mask_cp, num_elements))\n",
        "    cp.cuda.runtime.deviceSynchronize()  # Ensure the GPU has completed processing\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Retrieve filtered data from GPU\n",
        "    mask_np = cp.asnumpy(mask_cp)\n",
        "    filtered_indices = np.where(mask_np == 1)[0]\n",
        "\n",
        "    print(f\"Filtering completed: {len(filtered_indices)} entries matched\")\n",
        "\n",
        "    # Write the filtered results to a new CSV file\n",
        "    with open(output_file, 'w', newline='') as csvfile:\n",
        "        fieldnames = ['Longitude', 'Latitude', 'Altitude']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        with open(input_file, 'r') as csvfile:\n",
        "            reader = csv.DictReader(csvfile)\n",
        "            for i, row in enumerate(reader):\n",
        "                if i in filtered_indices:\n",
        "                    writer.writerow({\n",
        "                        'Longitude': row['Longitude'],\n",
        "                        'Latitude': row['Latitude'],\n",
        "                        'Altitude': row['Altitude']\n",
        "                    })\n",
        "\n",
        "    print(f\"Filtering execution time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Input and output files\n",
        "input_file = 'satellite_latlongalt_gpu.csv'\n",
        "output_file = 'filtered_satellite_positions_gpu.csv'\n",
        "\n",
        "# Call the function to filter results based on user input\n",
        "filter_results(input_file, output_file)\n"
      ],
      "metadata": {
        "id": "MZudm87C3orz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}